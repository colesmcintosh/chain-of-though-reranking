{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRL0o+moxVk9HceYljpDPJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colesmcintosh/chain-of-though-reranking/blob/main/chain_of_thought_reranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reranking Chain of Thought (COT)\n",
        "\n",
        "This notebook demonstrates how to generate, process, and rerank Chain of Thought (COT) responses using the `together` and `cohere` APIs. The process involves:\n",
        "\n",
        "1. Generating a response from a chatbot model.\n",
        "2. Extracting the COT reasoning from the response.\n",
        "3. Splitting the response into sentences and grouping them.\n",
        "4. Reranking the most relevant sections.\n",
        "5. Formatting the best-ranked documents into a structured prompt.\n",
        "6. Using the formatted prompt to generate a final refined response."
      ],
      "metadata": {
        "id": "MA7ZucoYAyZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Install Required Libraries**\n",
        "\n",
        "We first install `together` and `cohere`, which are needed to interact with the respective APIs.\n"
      ],
      "metadata": {
        "id": "g1nvQIOqA1za"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUQAQ0ra1sVv",
        "outputId": "509bbf70-73a7-4826-e0c4-d98d53daf085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: together in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.11/dist-packages (5.13.12)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.11)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from together) (0.2.2)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (1.26.4)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from together) (17.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.1)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.28.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install together cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Set Up API Keys**\n",
        "\n",
        "We retrieve the API keys from `google.colab.userdata` or prompt the user for input.\n"
      ],
      "metadata": {
        "id": "OsUbqu8oA5xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "cohere_api_key = userdata.get('COHERE_API_KEY') or input('COHERE_API_KEY:')\n",
        "together_api_key = userdata.get('TOGETHER_API_KEY') or input('TOGETHER_API_KEY:')"
      ],
      "metadata": {
        "id": "zjm35Roz3iD-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Initialize API Clients**\n",
        "\n",
        "We instantiate `cohere` and `together` clients.\n"
      ],
      "metadata": {
        "id": "GZQR_Rh2A9Ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "from together import Together\n",
        "co = cohere.Client(cohere_api_key)\n",
        "together_client = Together(api_key=together_api_key)"
      ],
      "metadata": {
        "id": "-r4oHUem3Oz5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Define the Initial Prompt**\n",
        "\n",
        "We define the reasoning task where a robot picks up objects and shakes hands with itself.\n"
      ],
      "metadata": {
        "id": "J-_ReEIoBHal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Which number is larger, 9.9 or 9.11?'"
      ],
      "metadata": {
        "id": "p_VmX9wj5RiU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary Test: Evaluate the Base LLM Response\n",
        "\n",
        "Before diving into the chain-of-thought (COT) extraction and reranking process, it is prudent to verify that the base LLM response to the initial prompt is incorrect. This test provides a baseline that will help us assess the improvements once we optimize the reasoning content. In this experiment, we query the model with our original prompt and display its direct output."
      ],
      "metadata": {
        "id": "dO_yLfc-XGFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_response = together_client.chat.completions.create(\n",
        "    model='meta-llama/Llama-3.2-3B-Instruct-Turbo',\n",
        "    messages=[{'role': 'user', 'content': prompt}],\n",
        ")"
      ],
      "metadata": {
        "id": "pQ1Fzn2mXJWi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fXPf-iwjXQUM",
        "outputId": "0b9cdf28-593d-4853-bd20-a5046dc7690f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'9.11 is larger than 9.9.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Generate a Chatbot Response**\n",
        "\n",
        "Using the DeepSeek-R1 model, we generate an initial response to get the chain of thought.\n"
      ],
      "metadata": {
        "id": "rHFM8XL1BK7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_response = together_client.chat.completions.create(\n",
        "    model='deepseek-ai/DeepSeek-R1',\n",
        "    messages=[{'role': 'user', 'content': prompt}],\n",
        ")\n"
      ],
      "metadata": {
        "id": "e0QZb1dV39n8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text = cot_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "pBTL4aVY5fGo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Extract the Chain of Thought (COT)**\n",
        "\n",
        "We extract the reasoning portion of the response by isolating the text between `<think>` and `</think>`."
      ],
      "metadata": {
        "id": "b0kaUMdMBZAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot = response_text.split('<think>')[1].split('</think>')[0]"
      ],
      "metadata": {
        "id": "zmLm0QRo50s7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "LCdLxA5mEmu3",
        "outputId": "a1fd8c23-73fb-41b5-b6a3-a5a4e8b72f4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nOkay, so I need to figure out which number is larger between 9.9 and 9.11. Hmm, let's start by writing them down to compare. \\n\\nFirst, I know that both numbers have the same whole number part, which is 9. That means the difference must be in the decimal parts. The first number is 9.9, and the second is 9.11. \\n\\nWait, but decimals can be tricky because the places matter. Let me break them down. \\n\\nFor 9.9, the decimal part is 0.9. That's the same as 0.90 if I add a zero at the end, right? Because 0.9 is nine tenths. \\n\\nOn the other hand, 9.11 has a decimal part of 0.11, which is eleven hundredths. So now, if I compare 0.90 and 0.11, it's easier to see. \\n\\n0.90 is definitely larger than 0.11 because 90 hundredths is more than 11 hundredths. So, putting that back into the original numbers, 9.90 is larger than 9.11. \\n\\nBut wait, let me double-check. Maybe I confused the decimal places. Let's think about it another way. \\n\\nIf I convert both numbers to fractions, maybe that will help. \\n\\n9.9 is the same as 9 + 9/10, which is 9 + 0.9. \\n\\n9.11 is 9 + 11/100, which is 9 + 0.11. \\n\\nComparing 9/10 and 11/100, which one is bigger? \\n\\nTo compare 9/10 and 11/100, I can convert them to have the same denominator. \\n\\n9/10 is equal to 90/100. \\n\\nSo, 90/100 compared to 11/100. \\n\\n90 is more than 11, so 90/100 is larger. \\n\\nTherefore, 9.9 is larger than 9.11. \\n\\nAnother way to think about it is by aligning the decimal points and adding trailing zeros to make them the same length:\\n\\n9.90\\n9.11\\n\\nStarting from the left, the whole number part is 9 in both. Then the tenths place: 9 vs. 1. Since 9 is greater than 1, 9.90 is already larger here. The hundredths place doesn't matter once the tenths place is different. \\n\\nSo, even though 9.11 has an extra digit, the tenths place of 9.9 is much higher, making it the larger number. \\n\\nI think that's solid. But just to be thorough, let's subtract them to see the difference. \\n\\n9.9 minus 9.11. \\n\\nTo subtract, line them up:\\n\\n9.90\\n-9.11\\n------\\n0.79\\n\\nSo, 9.9 is 0.79 more than 9.11, which confirms it's larger. \\n\\nAlternatively, if I had to compare them on a number line, 9.9 is closer to 10 than 9.11 is. Since 9.9 is just 0.1 away from 10, while 9.11 is 0.89 away from 10. So again, 9.9 is larger. \\n\\nWait, but sometimes people might get confused because 9.11 has two decimal places and think it's larger, but that's a common mistake. The key is that the first decimal place (tenths) is more significant than the second (hundredths). So even though 11 is more than 9, in decimals, the position matters. \\n\\nSo, in conclusion, after checking multiple ways—converting to fractions, aligning decimals, subtracting, and using the number line—it's clear that 9.9 is larger than 9.11.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Split COT into Sentences and Group Them**\n",
        "\n",
        "We define functions to split text into sentences and then group them into segments of four sentences.\n"
      ],
      "metadata": {
        "id": "B8JvjOM0Bgbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    \"\"\"\n",
        "    Splits the provided text into sentences using a regex that recognizes\n",
        "    common sentence-ending punctuation (periods, exclamation marks, and question marks).\n",
        "    \"\"\"\n",
        "    # The regex looks for punctuation followed by whitespace.\n",
        "    pattern = r'(?<=[.!?])\\s+'\n",
        "    sentences = re.split(pattern, text.strip())\n",
        "    return sentences\n",
        "\n",
        "def group_sentences(sentences, group_size=4):\n",
        "    \"\"\"\n",
        "    Aggregates the list of sentences into groups (chunks) containing group_size sentences each.\n",
        "    \"\"\"\n",
        "    return [' '.join(sentences[i:i+group_size]) for i in range(0, len(sentences), group_size)]\n"
      ],
      "metadata": {
        "id": "97cVwuIR9bTt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Process the Extracted Reasoning**\n",
        "\n",
        "We apply the sentence-splitting and grouping functions.\n"
      ],
      "metadata": {
        "id": "wEnKgdDaBogq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Split the text into individual sentences.\n",
        "sentences = split_into_sentences(cot)\n",
        "\n",
        "# Step 2: Group the sentences into chunks, with each chunk containing 4 sentences.\n",
        "chunks = group_sentences(sentences, group_size=4)\n",
        "\n",
        "# Display the resulting chunks.\n",
        "for index, chunk in enumerate(chunks, start=1):\n",
        "    print(f\"Chunk {index}:\\n{chunk}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEMT1Xhr59cx",
        "outputId": "076e916b-50e6-4ba8-ec98-044952f8e902"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "Okay, so I need to figure out which number is larger between 9.9 and 9.11. Hmm, let's start by writing them down to compare. First, I know that both numbers have the same whole number part, which is 9. That means the difference must be in the decimal parts.\n",
            "\n",
            "Chunk 2:\n",
            "The first number is 9.9, and the second is 9.11. Wait, but decimals can be tricky because the places matter. Let me break them down. For 9.9, the decimal part is 0.9.\n",
            "\n",
            "Chunk 3:\n",
            "That's the same as 0.90 if I add a zero at the end, right? Because 0.9 is nine tenths. On the other hand, 9.11 has a decimal part of 0.11, which is eleven hundredths. So now, if I compare 0.90 and 0.11, it's easier to see.\n",
            "\n",
            "Chunk 4:\n",
            "0.90 is definitely larger than 0.11 because 90 hundredths is more than 11 hundredths. So, putting that back into the original numbers, 9.90 is larger than 9.11. But wait, let me double-check. Maybe I confused the decimal places.\n",
            "\n",
            "Chunk 5:\n",
            "Let's think about it another way. If I convert both numbers to fractions, maybe that will help. 9.9 is the same as 9 + 9/10, which is 9 + 0.9. 9.11 is 9 + 11/100, which is 9 + 0.11.\n",
            "\n",
            "Chunk 6:\n",
            "Comparing 9/10 and 11/100, which one is bigger? To compare 9/10 and 11/100, I can convert them to have the same denominator. 9/10 is equal to 90/100. So, 90/100 compared to 11/100.\n",
            "\n",
            "Chunk 7:\n",
            "90 is more than 11, so 90/100 is larger. Therefore, 9.9 is larger than 9.11. Another way to think about it is by aligning the decimal points and adding trailing zeros to make them the same length:\n",
            "\n",
            "9.90\n",
            "9.11\n",
            "\n",
            "Starting from the left, the whole number part is 9 in both. Then the tenths place: 9 vs.\n",
            "\n",
            "Chunk 8:\n",
            "1. Since 9 is greater than 1, 9.90 is already larger here. The hundredths place doesn't matter once the tenths place is different. So, even though 9.11 has an extra digit, the tenths place of 9.9 is much higher, making it the larger number.\n",
            "\n",
            "Chunk 9:\n",
            "I think that's solid. But just to be thorough, let's subtract them to see the difference. 9.9 minus 9.11. To subtract, line them up:\n",
            "\n",
            "9.90\n",
            "-9.11\n",
            "------\n",
            "0.79\n",
            "\n",
            "So, 9.9 is 0.79 more than 9.11, which confirms it's larger.\n",
            "\n",
            "Chunk 10:\n",
            "Alternatively, if I had to compare them on a number line, 9.9 is closer to 10 than 9.11 is. Since 9.9 is just 0.1 away from 10, while 9.11 is 0.89 away from 10. So again, 9.9 is larger. Wait, but sometimes people might get confused because 9.11 has two decimal places and think it's larger, but that's a common mistake.\n",
            "\n",
            "Chunk 11:\n",
            "The key is that the first decimal place (tenths) is more significant than the second (hundredths). So even though 11 is more than 9, in decimals, the position matters. So, in conclusion, after checking multiple ways—converting to fractions, aligning decimals, subtracting, and using the number line—it's clear that 9.9 is larger than 9.11.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. Perform Reranking Using Cohere**\n",
        "\n",
        "We rerank the sentence chunks using Cohere’s rerank model (`rerank-v3.5`).\n"
      ],
      "metadata": {
        "id": "8k5m2I_FBvxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reranking = co.rerank(\n",
        "    model=\"rerank-v3.5\", query=prompt, documents=chunks, top_n=5\n",
        ")"
      ],
      "metadata": {
        "id": "7QIqPvZj7HMe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for res in reranking.results:\n",
        "  print(chunks[res.index])\n",
        "  print(f\"Relevance Score: {res.relevance_score:.2%}\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ13ZUlf7pq7",
        "outputId": "986e5125-7279-45bc-ad4b-1565c6035a11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternatively, if I had to compare them on a number line, 9.9 is closer to 10 than 9.11 is. Since 9.9 is just 0.1 away from 10, while 9.11 is 0.89 away from 10. So again, 9.9 is larger. Wait, but sometimes people might get confused because 9.11 has two decimal places and think it's larger, but that's a common mistake.\n",
            "Relevance Score: 95.26%\n",
            "\n",
            "The key is that the first decimal place (tenths) is more significant than the second (hundredths). So even though 11 is more than 9, in decimals, the position matters. So, in conclusion, after checking multiple ways—converting to fractions, aligning decimals, subtracting, and using the number line—it's clear that 9.9 is larger than 9.11.\n",
            "Relevance Score: 93.45%\n",
            "\n",
            "90 is more than 11, so 90/100 is larger. Therefore, 9.9 is larger than 9.11. Another way to think about it is by aligning the decimal points and adding trailing zeros to make them the same length:\n",
            "\n",
            "9.90\n",
            "9.11\n",
            "\n",
            "Starting from the left, the whole number part is 9 in both. Then the tenths place: 9 vs.\n",
            "Relevance Score: 92.64%\n",
            "\n",
            "1. Since 9 is greater than 1, 9.90 is already larger here. The hundredths place doesn't matter once the tenths place is different. So, even though 9.11 has an extra digit, the tenths place of 9.9 is much higher, making it the larger number.\n",
            "Relevance Score: 92.33%\n",
            "\n",
            "I think that's solid. But just to be thorough, let's subtract them to see the difference. 9.9 minus 9.11. To subtract, line them up:\n",
            "\n",
            "9.90\n",
            "-9.11\n",
            "------\n",
            "0.79\n",
            "\n",
            "So, 9.9 is 0.79 more than 9.11, which confirms it's larger.\n",
            "Relevance Score: 91.99%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10. Format the Top Ranked Documents into a Structured Prompt**\n",
        "\n",
        "We define a function to format the most relevant chunks into a refined prompt.\n"
      ],
      "metadata": {
        "id": "s_fsvyOSCUsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_documents_into_prompt(documents):\n",
        "    \"\"\"\n",
        "    Formats a list of document dictionaries into a unified prompt string.\n",
        "\n",
        "    Each document has these keys:\n",
        "      - 'index': the document's index (used for ordering)\n",
        "      - 'relevance_score': a numeric score indicating relevance\n",
        "\n",
        "    The function sorts the documents by their index in ascending order and\n",
        "    constructs a prompt that clearly displays each document's index, relevance score,\n",
        "    and text.\n",
        "    \"\"\"\n",
        "    # Sort the documents by 'relevance_score'\n",
        "    sorted_docs = sorted(documents, key=lambda doc: doc.relevance_score)\n",
        "\n",
        "    # Build the prompt with a header and each document's details\n",
        "    prompt_lines = [\"Consider the following thoughts:\\n\"]\n",
        "    for doc in sorted_docs:\n",
        "        index = doc.index\n",
        "        relevance = doc.relevance_score\n",
        "        text = chunks[index]\n",
        "        prompt_lines.append(f\"Thought (index {index}, relevance: {relevance:.2%}):\\n{text}\\n\")\n",
        "\n",
        "    # Join the individual parts into a single prompt string\n",
        "    prompt = \"\\n\".join(prompt_lines)\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "BpJknux07qqg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents_prompt = format_documents_into_prompt(reranking.results)"
      ],
      "metadata": {
        "id": "jzN0qRF--cYA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "t_tmC-dp-n-e",
        "outputId": "48bca39d-3ba7-4743-ae79-dede0ab99de1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Consider the following thoughts:\\n\\nThought (index 8, relevance: 91.99%):\\nI think that's solid. But just to be thorough, let's subtract them to see the difference. 9.9 minus 9.11. To subtract, line them up:\\n\\n9.90\\n-9.11\\n------\\n0.79\\n\\nSo, 9.9 is 0.79 more than 9.11, which confirms it's larger.\\n\\nThought (index 7, relevance: 92.33%):\\n1. Since 9 is greater than 1, 9.90 is already larger here. The hundredths place doesn't matter once the tenths place is different. So, even though 9.11 has an extra digit, the tenths place of 9.9 is much higher, making it the larger number.\\n\\nThought (index 6, relevance: 92.64%):\\n90 is more than 11, so 90/100 is larger. Therefore, 9.9 is larger than 9.11. Another way to think about it is by aligning the decimal points and adding trailing zeros to make them the same length:\\n\\n9.90\\n9.11\\n\\nStarting from the left, the whole number part is 9 in both. Then the tenths place: 9 vs.\\n\\nThought (index 10, relevance: 93.45%):\\nThe key is that the first decimal place (tenths) is more significant than the second (hundredths). So even though 11 is more than 9, in decimals, the position matters. So, in conclusion, after checking multiple ways—converting to fractions, aligning decimals, subtracting, and using the number line—it's clear that 9.9 is larger than 9.11.\\n\\nThought (index 9, relevance: 95.26%):\\nAlternatively, if I had to compare them on a number line, 9.9 is closer to 10 than 9.11 is. Since 9.9 is just 0.1 away from 10, while 9.11 is 0.89 away from 10. So again, 9.9 is larger. Wait, but sometimes people might get confused because 9.11 has two decimal places and think it's larger, but that's a common mistake.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **11. Generate a Final Response Using a smaller LLM**\n",
        "\n",
        "We concatenate the refined prompt with the original question and generate a final response."
      ],
      "metadata": {
        "id": "AgNai6_bCn7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reranked_prompt = prompt + \"\\n\" + documents_prompt"
      ],
      "metadata": {
        "id": "gCptijuB-1Vb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reranked_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ocNZx6e5DOg6",
        "outputId": "d6702854-ad41-4137-f413-d4ed5c19167a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Which number is larger, 9.9 or 9.11?\\nConsider the following thoughts:\\n\\nThought (index 8, relevance: 91.99%):\\nI think that's solid. But just to be thorough, let's subtract them to see the difference. 9.9 minus 9.11. To subtract, line them up:\\n\\n9.90\\n-9.11\\n------\\n0.79\\n\\nSo, 9.9 is 0.79 more than 9.11, which confirms it's larger.\\n\\nThought (index 7, relevance: 92.33%):\\n1. Since 9 is greater than 1, 9.90 is already larger here. The hundredths place doesn't matter once the tenths place is different. So, even though 9.11 has an extra digit, the tenths place of 9.9 is much higher, making it the larger number.\\n\\nThought (index 6, relevance: 92.64%):\\n90 is more than 11, so 90/100 is larger. Therefore, 9.9 is larger than 9.11. Another way to think about it is by aligning the decimal points and adding trailing zeros to make them the same length:\\n\\n9.90\\n9.11\\n\\nStarting from the left, the whole number part is 9 in both. Then the tenths place: 9 vs.\\n\\nThought (index 10, relevance: 93.45%):\\nThe key is that the first decimal place (tenths) is more significant than the second (hundredths). So even though 11 is more than 9, in decimals, the position matters. So, in conclusion, after checking multiple ways—converting to fractions, aligning decimals, subtracting, and using the number line—it's clear that 9.9 is larger than 9.11.\\n\\nThought (index 9, relevance: 95.26%):\\nAlternatively, if I had to compare them on a number line, 9.9 is closer to 10 than 9.11 is. Since 9.9 is just 0.1 away from 10, while 9.11 is 0.89 away from 10. So again, 9.9 is larger. Wait, but sometimes people might get confused because 9.11 has two decimal places and think it's larger, but that's a common mistake.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_response = together_client.chat.completions.create(\n",
        "    model='meta-llama/Llama-3.2-3B-Instruct-Turbo',\n",
        "    messages=[{'role': 'user', 'content': reranked_prompt}],\n",
        ")"
      ],
      "metadata": {
        "id": "d35TPpEZ_3uW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Sr1uhgnqALZn",
        "outputId": "cdbe28be-1b48-4935-ffbe-8e028cdedfd6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The number 9.9 is larger than 9.11. \\n\\nThe reasoning provided in the thoughts is consistent and accurate. The key points are:\\n\\n1. Subtracting 9.11 from 9.9 results in 0.79, confirming that 9.9 is larger.\\n2. The tenths place of 9.9 is higher than the tenths place of 9.11.\\n3. Aligning the decimal points and adding trailing zeros makes 9.90 larger than 9.11.\\n4. The position of the decimal places matters, with the tenths place being more significant than the hundredths place.\\n5. Comparing the numbers on a number line shows that 9.9 is closer to 10 than 9.11 is.\\n\\nAll these points support the conclusion that 9.9 is indeed larger than 9.11.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook has demonstrated a method to refine the chain-of-thought output by isolating and reranking its components. The strategy involves:\n",
        "- Extracting the internal reasoning (COT) from the raw LLM response.\n",
        "- Splitting and grouping the reasoning into manageable chunks.\n",
        "- Reranking these chunks based on relevance to the prompt.\n",
        "- Reconstructing a refined prompt that minimizes contradictory thoughts and potentially reduces token usage.\n",
        "\n",
        "By selecting only the most coherent and pertinent pieces of the chain-of-thought, we can optimize the information fed back to the LLM, leading to more reliable and concise final outputs. This approach paves the way for further experiments aimed at reducing ambiguity and streamlining token consumption in LLM interactions."
      ],
      "metadata": {
        "id": "EVSDyhnOcuB3"
      }
    }
  ]
}